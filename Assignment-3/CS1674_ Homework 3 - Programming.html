<html><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>CS1674: Homework 3 - Programming</title>
</head>
<body>
<h2>CS1674: Homework 3 - Programming</h2>
<b>Due:</b> 9/21/2016, 11:59pm 
<br><br>

This assignment is worth 50 points. I estimate it would take you about 
2-4 hours to complete if you understood the past few lectures.
<br><br>

<u>Part I: Image Representation with Filters</u> (25 points) [should take you 1-3hrs]
<br><br>
In this problem, you will use texture to represent images. For each 
image, you will compute the response of each image pixel to the filters 
from a "filter bank" as discussed in class. You will then compute a 
histogram and mean of these values for each image, and compare the 
histograms or means across images of the same or different categories. 
<ol>
<li>Download these images:
<a href="https://people.cs.pitt.edu/%7Ekovashka/cs1674/cardinal1.jpg">cardinal1</a>, 
<a href="https://people.cs.pitt.edu/%7Ekovashka/cs1674/cardinal2.jpg">cardinal2</a>, 
<a href="https://people.cs.pitt.edu/%7Ekovashka/cs1674/leopard1.jpg">leopard1</a>, 
<a href="https://people.cs.pitt.edu/%7Ekovashka/cs1674/leopard2.jpg">leopard2</a>, 
<a href="https://people.cs.pitt.edu/%7Ekovashka/cs1674/panda1.jpg">panda1</a>, 
<a href="https://people.cs.pitt.edu/%7Ekovashka/cs1674/panda2.jpg">panda2</a>.
 As you can see, there are two images for each of three animal 
categories. Use a cell array to store the image filenames in Matlab, so 
you can use matrix/vector indices to refer to the k-th image. For 
simplicity, convert all images to the same square size (e.g. 512x512).</li>
<li>Download the <a href="http://www.robots.ox.ac.uk/%7Evgg/research/texclass/code/makeLMfilters.m">Leung-Malik filter bank code</a> (one function) and read the description at the top of how to run it. Run the code to obtain the filter bank <font face="courier new">F</font>. You only need to do this once.</li>
<li>For each image, you need to do the following. First, read in the image, <font color="red">convert it to grayscale</font>, and reduce its size by 0.5 or 0.25 (the smaller the faster it will be to convolve) using Matlab's <font face="courier new">imresize</font>. Then convolve each pixel in your image with each of the 48 filters. i.e. with each <font face="courier new">F(:, :, i)</font>. This would allow you to generate images like the responses to the Capitol image shown in class. Use the function <font face="courier new">imfilter(image, filter)</font>. For three of the six images, show the response of the image to each filter, using subplots <font color="red">and imagesc</font>. An example is shown below.</li>
<br><br>
<img src="CS1674_%20Homework%203%20-%20Programming_files/capitol.jpg" height="400"> <img src="CS1674_%20Homework%203%20-%20Programming_files/filt1.png" height="400"> <img src="CS1674_%20Homework%203%20-%20Programming_files/filt2.png" height="400"> <img src="CS1674_%20Homework%203%20-%20Programming_files/filt4.png" height="400"> <img src="CS1674_%20Homework%203%20-%20Programming_files/filt37.png" height="400"> <img src="CS1674_%20Homework%203%20-%20Programming_files/filt45.png" height="400">   
<!--Note that <font face="courier new">im = imread([image filename]); im = rgb2gray(im);</font> is an image read into Matlab and converted to grayscale.</li>-->
<li>For each image, compute a histogram over the filter responses. Let <font face="courier new">filt_im = imfilter(im, F(:, :, j)); filt_im = filt_im(:);</font> be the vector containing the responses to the i-th filter. Use <font face="courier new">histc</font> to compute a histogram over the responses, after fixing the bin edges<font color="red">/ranges</font> to <font face="courier new">2.^(0:0.5:7)</font>.
 Then concatenate the histograms for all filters, resulting in a 1x720 
vector. This vector is now the descriptor for the image. You will have 
one descriptor per image.</li> 
<li>Now compute the Euclidean distance between pairs of images. As 
discussed in class, Euclidean distance measures the square root of the 
sum of the squared element-wise distances between the image descriptors.
 Initialize (set to <font face="courier new">[]</font>) one variable to 
store within-category distances (distances between images that are of 
the same animal category), and another to store between-category 
distances (distance between images showing different animal categories).
 Then iterate over the image pairs and concatenate the distance for that
 image pair to the correct (within_ or between_) variable.</li>
<li>Print the mean of the within-category and between-category 
distances. Which one is smaller? By how much? Is this what you would 
expect? Why or why not? Answer these questions in a text file called <font face="courier new">responses.txt</font> which you include in your submission zip file.</li> 
<li>Now let's compute the image represenation in a different way, again 
using filters. However, rather than computing a histogram, each image's 
representation will be the mean response across all pixels to each of 
the filters, resulting in one mean value per filter and an overall image
 representation of size 1x48. Repeat the process above to compute 
within-category and between-category distances. Now how does average 
within-category and between-category distance compare? Is this more in 
line with what you would expect?</li>
<li>Finally, let's just use the image pixels i.e. <font face="courier new">im(:)</font>
 as the representation/description. Compute a histogram as for the 
texture histogram representation (the first one you tried), and use <font face="courier new">0:5:255</font> as the bin edges. Compute within-/between-category distances again.</li>
<li>Which of the three types of descriptors that you used is the best 
one? How can you tell? Include your reasoning in your response. Don't 
worry about whether you get the answer that I expect, I care more about 
your reasoning than the actual answer, and your response in the text 
file mentioned above.</li>
<li>Include all your code in a script <font face="courier new">compare_filter_responses.m</font>.</li>
</ol>

<!--use cell array
show responses for 3 images 
histogram range 
compute dists within/outside pair 
imresize
use imfilter-->


<br><br>


<u>Part II: Hybrid Images</u> (10 points) [should take you 5-15 min if you understood the hybrid image example]
<br><br>
In this problem, you will create a hybrid image (which looks like one 
thing zoomed in and another zoomed out) like the one shown in class. 
<ol>
<li>Download one pair of images: <a href="https://people.cs.pitt.edu/%7Ekovashka/cs1674/woman_happy.png">woman_happy</a> and <a href="https://people.cs.pitt.edu/%7Ekovashka/cs1674/woman_neutral.png">woman_neutral</a>, or <a href="https://people.cs.pitt.edu/%7Ekovashka/cs1674/baby_happy.jpg">baby_happy</a> and <a href="https://people.cs.pitt.edu/%7Ekovashka/cs1674/baby_weird.jpg">baby_weird</a>.</li>
<li>In your code, read in both images and resize them to the same square
 size (e.g. 512x512). Also convert both of them to grayscale. Name your 
script <font face="courier new">hybrid_image.m</font>.</li>
<li>Create a Gaussian filter with <font face="courier new">fspecial('gaussian', hsize, sigma);</font></li>
<li>Apply the filter to both, saving the results as <font face="courier new">im1_blur, im2_blur</font>.</li>
<li>For the second image, subtract the blur of the image from the image 
(as we did with the Pittsburgh image in class), and save the result as <font face="courier new">im2_detail</font>.</li>
<li>Now add <font face="courier new">im1_blur</font> and <font face="courier new">im2_detail</font>,
 show the image, save it, and include it with your submission. Play with
 scaling it up and down (by dragging in Matlab) to see the "hybrid" 
effect.</li>

</ol>

<br><br>

<u>Part III Image Pyramids</u> (15 points) [should take you 30min-1hr if you understood image pyramids]
<br><br>
In this problem, you will illustrate different levels of detail in an image, using image pyramids, as discussed in class. <!--You will also reconstruct a high-resolution image from a low-resolution one.-->
<ol>
<li>Choose an image that has an interesting variety of texture (from 
Flickr/Google/Bing or your own images). The image should be at least 640x480 pixels 
and converted to grayscale. Use the Matlab function <font face="courier new">rgb2gray</font>. 
<!--For simplicity, resize the image to 256x256 or 512x512 as soon as you load it.--></li>
<li>Write code for a Gaussian and Laplacian pyramids of level N (use <font face="courier new">for</font>
loops). In each level, the resolution should be reduced by a factor of 
2. As discussed in class, before each subsampling, the image should be blurred; use the Matlab function <font face="courier new">imfilter</font>.</li>
<li>To compute the Laplacian at each stage, remember that your images 
(pre- and post-blurring) should be of the same size, but the image you 
store in the actual pyramid should be scaled down by a factor of 2.</li>
<li>To scale an image down, simply ignore every other pixel. For 
example, you can retrieve only pixels in increments of 2. In Matlab, the
 way to do that is e.g. <font face="courier new">im = im(1:2:end, 1:2:end);</font></li>
<li>Use the same filter at each step.</li>
<li>Your code should include a function with signature <font face="courier new">[G, L] = pyramids(im, fil);</font>, where <font face="courier new">G</font> is the Gaussian pyramid and <font face="courier new">L</font> is the Laplacian pyramid, while <font face="courier new">im</font> is a grayscale image and <font face="courier new">fil</font> is the output of <font face="courier new">fspecial('gaussian', hsize, sigma)</font>. <font face="courier new">G</font> should be a cell array such that <font face="courier new">G{i}</font> returns the i-th level of the Gaussian pyramid. Similarly <font face="courier new">L{i}</font> should return the i-th level of the Laplacian pyramid.</li>
<!--Use the Matlab functions <font face="courier new">figure</font> and <font face="courier new">imagesc(im,[minval maxval])</font>.-->

<!--<li>Finally, your code should reconstruct the original image from the Laplacian pyramid, as discussed in class. Because of this, you should follow the exact set of steps given in class (slide "Detailed set of steps for HW3P" on 9/14) to construct your pyramid, and invert them starting from the last level of the Laplacian image, to reconstruct the image. You will take the image in the last level of the Laplacian pyramid, upsample it using <font face="courier new">imresize(im, 2, 'nearest')</font> and filter it, then add to it the image at the preceding level of the Laplacian pyramid, and repeat. Use the function signature <font face="courier new">[recon_im] = reconstruct_image(L, fil);</font> </li>-->
<li>Set <font face="courier new">L{n} = G{n};</font></li>
<li>Your code should also include a script titled <font face="courier new">image_pyramids.m</font> that loads the image, runs the <font face="courier new">pyramids</font>
 code, and shows the pyramids. Show a Gaussian and Laplacian pyramid of 
level 5 for your chosen image using your code. You can show each <font face="courier new">G{i}</font> and <font face="courier new">L{i}</font> separately, resulting in 10 separate figures which you label appropriately using <font face="courier new">title</font>, or you can show them together in 1 subplot with 10 figures or 2 subplots with 5 figures.  
You can (but don't have to) also use the <a href="http://people.cs.pitt.edu/%7Ekovashka/cs1699/tight_subplot.m"><font face="Courier New">tight_subplot</font></a>
 function to format your plot. Your displayed images for the Gaussian 
and Laplacian pyramids should look something like the image below. The image at the bottom-right can be skipped. 
<!--Also run your reconstruction code in the script, and compute the sum of the pixel-wise distances between the original and reconstructed images. If you follow the approach given in class, your original and reconstructed images should be identical.--></li>
<li>Also include the original image you chose and the image pyramid figure(s)
<!--, and your reconstructed original image,
--> in your submission.</li>
<br>
<img src="CS1674_%20Homework%203%20-%20Programming_files/lake_pyramids.png">
</ol>
 


<!--
<u>Part II: Feature Detection (30 points)</u> 
<br><br>
In this problem, you will implement feature extraction using the Harris corner detector, as discussed in class. 
<ol>
<li>Use the following signature: <font face="courier new">function [x, y, scores, Gx, Gy] = extract_keypoints(image);</font> <font face="courier new">image</font> is a color image of type <font face="courier new">uint8</font> which you should convert to grayscale and <font face="courier new">double</font> in your function. Each of <font face="courier new">x,y</font> is an <i>n</i>x1 vector that denotes the x and y locations, respectively, of each of the <i>n</i> detected keypoints. Keep in mind that <i>x</i> denotes the horizontal direction, hence <i>columns</i> of the image, and <i>y</i> denotes the vertical direction, hence <i>rows</i>, counting from the top-left of the image. <font face="courier new">scores</font> is an <i>n</i>x1 vector that contains the value to which you applied a threshold, for each detected keypoint. <font face="courier new">Gx,Gy</font> are matrices with the same 
number of rows and columns as your input image, and store the gradients 
in the x and y directions at each pixel. You can reuse code to compute gradients from HW2P, and you will need these <font face="courier new">Gx,Gy</font> outputs for the next homework. </li>
<li>You can use a window function of your choice; opt for the simplest one, e.g. the 1 inside, 0 outside one from class. Use a window size of e.g. 5 pixels. </li>
<li>You should also perform non-maximum suppression by only keeping those keypoints whose <i>R</i>
 score is larger than all of their 8 neighbors; if a keypoint does not 
have 8 neighbors, do not keep it. Don't remove indices while looping 
over pixels; instead keep a vector of indices you want to remove (start 
it empty and concatenate indices to it as needed), run the <font face="courier new">unique</font> operation on it, then set the keypoints at those indices to <font face="courier new">[]</font>. The <font face="courier new">scores/x/y</font> that you output should correspond to the final set of keypoints, after non-max suppression.</li>
<li>You can set the threshold for the "cornerness" score <i>R</i> however you like; for example, you can set it to 5 times the average <i>R</i> score. Alternatively, you can simply output the top <i>n</i> keypoints (e.g. top 1%).</li>
<li>After you have written your <font face="courier new">extract_keypoints</font> function, show what it does on a set of 10 images of your choice. Do this in a script called <font face="courier new">show_keypoints.m</font>. Visualize the keypoints you have detected, for example by drawing circles over them. Use the scores variable and make keypoints with higher scores correspond to larger circles. For example, you can use <font face="courier new">plot(x(i), y(i), 'ro', 'MarkerSize', scores(i) / 1000000000);</font> Note that Matlab's plot counts from the top-left when plotting over an image. Save the figures that show your features and include them with your submission.</li>
</ol>
-->

<b>Acknowledgement:</b> Part III is adapted from Derek Hoiem.
<!--Part II was inspired in part by an assignment by James Hays.-->

<br><br>


</body></html>